# Database Configuration
# SQLite database file (no setup required, works out of the box)
DATABASE_URL="file:./prisma/dev.db"

# Recipe Generation Configuration
# Provider: 'ollama' (local) or 'gemini' (cloud)
RECIPE_PROVIDER="ollama"

# Ollama Configuration (for local LLM)
# Base URL for Ollama API (default: http://localhost:11434)
OLLAMA_BASE_URL="http://localhost:11434"
# Model to use (default: llama3.2)
OLLAMA_MODEL="llama3.2"

# Google Gemini Configuration (for cloud LLM - optional fallback)
# Get your API key from: https://aistudio.google.com/app/apikey
# Free tier: 15 requests/minute
# GEMINI_API_KEY="your_api_key_here"

# Optional: Node Environment
# Set to 'development' for local development, 'production' for deployment
# NODE_ENV="development"