# Database Configuration
# PostgreSQL connection string for Prisma ORM
# Format: postgresql://[user]:[password]@[host]:[port]/[database]?schema=[schema]
# Replace 'user', 'password', 'localhost', and '5432' with your PostgreSQL credentials
DATABASE_URL="postgresql://user:password@localhost:5432/meal_planner?schema=public"

# Spoonacular API Configuration (DEPRECATED - Using LLM now)
# Get your API key from: https://spoonacular.com/food-api
# Free tier includes 150 requests/day (enough for ~7 meal plans)
# Each meal plan generation uses approximately 21 API calls (7 days Ã— 3 meals)
# SPOONACULAR_API_KEY="your_api_key_here"

# Recipe Generation Configuration
# Provider: 'ollama' (local) or 'gemini' (cloud)
RECIPE_PROVIDER="ollama"

# Ollama Configuration (for local LLM)
# Base URL for Ollama API (default: http://localhost:11434)
OLLAMA_BASE_URL="http://localhost:11434"
# Model to use (default: llama3.2)
OLLAMA_MODEL="llama3.2"

# Google Gemini Configuration (for cloud LLM - optional fallback)
# Get your API key from: https://aistudio.google.com/app/apikey
# Free tier: 15 requests/minute
# GEMINI_API_KEY="your_api_key_here"

# Optional: Node Environment
# Set to 'development' for local development, 'production' for deployment
# NODE_ENV="development"